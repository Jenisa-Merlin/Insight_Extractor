{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"p_sphFaPu6rL"},"outputs":[],"source":["# install necessary libraries and dependencies\n","!pip install beautifulsoup4 pandas"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"eMVCIA1gigAa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import necessary libraries\n","import os\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.corpus import cmudict, stopwords\n","import re"],"metadata":{"id":"jjJg378EnFCs","executionInfo":{"status":"ok","timestamp":1715261616928,"user_tz":-330,"elapsed":19,"user":{"displayName":"21PW08 - JENISA MERLIN D","userId":"12343322897619244934"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('cmudict')"],"metadata":{"id":"yKj1G-vN5As6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function used to extract data from the website\n","def extractArticleText(url):\n","  try:\n","    # response for the url using html parser\n","    response = requests.get(url)\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","    # extract title\n","    title = soup.find('title').get_text().strip()\n","    # extract main text content\n","    articleText = \"\"\n","    mainContent = soup.find('div', class_='article-content')\n","    if mainContent:\n","      for paragraph in mainContent.find_all('p'):\n","        articleText += paragraph.get_text() + \"\\n\"\n","    else:\n","      for paragraph in soup.find_all('p'):\n","        articleText += paragraph.get_text() + \"\\n\"\n","    return title, articleText\n","  except Exception as e:\n","    print(f\"Error extracting text from {url}: {str(e)}\")\n","    return None, None"],"metadata":{"id":"KJhDi_Q5nYhd","executionInfo":{"status":"ok","timestamp":1715261616928,"user_tz":-330,"elapsed":12,"user":{"displayName":"21PW08 - JENISA MERLIN D","userId":"12343322897619244934"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Sentiment analysis\n","def calculateSentiment(text, positiveWords, negativeWords):\n","  positiveScore = sum(1 for word in text if word in positiveWords)\n","  negativeScore = (-1) * sum(-1 for word in text if word in negativeWords)\n","  polarityScore = (positiveScore - negativeScore) / ((positiveScore + negativeScore) + 0.000001)\n","  subjectivityScore = (positiveScore + negativeScore) / (len(text) + 0.000001)\n","  return positiveScore, negativeScore, polarityScore, subjectivityScore"],"metadata":{"id":"HUgpznmJ5JS3","executionInfo":{"status":"ok","timestamp":1715261616929,"user_tz":-330,"elapsed":12,"user":{"displayName":"21PW08 - JENISA MERLIN D","userId":"12343322897619244934"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Load CMU Pronouncing Dictionary for syllable counting\n","cmuDict = cmudict.dict()\n","stopWords = set(stopwords.words('english'))\n","\n","# function for counting syllables\n","def countSyllables(word):\n","  if word.lower() in cmuDict:\n","    return max([len(list(y for y in x if y[-1].isdigit())) for x in cmuDict[word.lower()]])\n","  else:\n","    return len(word) // 2"],"metadata":{"id":"Wc0ltL4h9VXO","executionInfo":{"status":"ok","timestamp":1715261620091,"user_tz":-330,"elapsed":3173,"user":{"displayName":"21PW08 - JENISA MERLIN D","userId":"12343322897619244934"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# readability analysis\n","def calculateReadability(text):\n","  words = word_tokenize(text)\n","  sentences = sent_tokenize(text)\n","  wordCount = len(words)\n","  sentenceCount = len(sentences)\n","  avgSentenceLength = wordCount / sentenceCount if sentenceCount > 0 else 0\n","  complexWordCount = sum(1 for word in words if countSyllables(word) > 2)\n","  complexWordsPercentage = (complexWordCount / wordCount)\n","  fogIndex = 0.4 * (avgSentenceLength + complexWordsPercentage)\n","  avgWordsPerSentence = wordCount / sentenceCount if sentenceCount > 0 else 0\n","  syllablePerWord = sum(countSyllables(word) for word in words) / wordCount if wordCount > 0 else 0\n","  personalPronouns = sum(1 for word in words if word.lower() in ['i', 'me', 'my', 'mine', 'we', 'us', 'our', 'ours'])\n","  avgWordLength = sum(len(word) for word in words) / wordCount if wordCount > 0 else 0\n","  return avgSentenceLength, complexWordsPercentage, fogIndex, avgWordsPerSentence, complexWordCount, wordCount, syllablePerWord, personalPronouns, avgWordLength"],"metadata":{"id":"lhZr1Ln76C3n","executionInfo":{"status":"ok","timestamp":1715261620092,"user_tz":-330,"elapsed":8,"user":{"displayName":"21PW08 - JENISA MERLIN D","userId":"12343322897619244934"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# main function\n","def main():\n","  inputFile = \"/content/drive/MyDrive/BLACKCOFFER SOLUTION/Input.xlsx\"\n","  extractionFolder = \"/content/drive/MyDrive/BLACKCOFFER SOLUTION/Extracted_Articles/\"\n","\n","  # create folder if not exists\n","  if not os.path.exists(extractionFolder):\n","    os.makedirs(extractionFolder)\n","\n","  # read URLs from Excel file\n","  df = pd.read_excel(inputFile)\n","\n","  for index, row in df.iterrows():\n","    urlID = row['URL_ID']\n","    url = row['URL']\n","    title, articleText = extractArticleText(url)\n","\n","    if title and articleText:\n","      with open(extractionFolder + f\"{urlID}.txt\", 'w', encoding='utf-8') as f:\n","        f.write(f\"Title: {title}\\n\\n\")\n","        f.write(articleText)\n","      print(f\"Article extracted from {url} and saved as {urlID}.txt\")\n","    else:\n","      print(f\"Failed to extract article from {url}\")\n","\n","  stopWordsFolder = \"/content/drive/MyDrive/BLACKCOFFER SOLUTION/StopWords/\"\n","\n","  # load stop words\n","  stopWordsList = set()\n","  for stopFileName in os.listdir(stopWordsFolder):\n","    try:\n","      with open(os.path.join(stopWordsFolder, stopFileName), 'r', encoding='utf-8') as stopFile:\n","        stopWordsList.update(stopFile.read().splitlines())\n","    except UnicodeDecodeError:\n","      with open(os.path.join(stopWordsFolder, stopFileName), 'r', encoding='latin-1') as stopFile:\n","        stopWordsList.update(stopFile.read().splitlines())\n","\n","  masterDictionaryFolder = \"/content/drive/MyDrive/BLACKCOFFER SOLUTION/MasterDictionary/\"\n","  positiveWordsPath = \"/content/drive/MyDrive/BLACKCOFFER SOLUTION/MasterDictionary/positive-words.txt\"\n","  negativeWordsPath = \"/content/drive/MyDrive/BLACKCOFFER SOLUTION/MasterDictionary/negative-words.txt\"\n","\n","  # positive and negative dictionary\n","  positiveWords = set()\n","  negativeWords = set()\n","\n","  # Load positive words from file\n","  with open(positiveWordsPath, 'r', encoding='utf-8') as file:\n","    for line in file:\n","      word = line.strip()\n","      if word:\n","        positiveWords.add(word.lower())\n","\n","  # Load negative words from file\n","  with open(negativeWordsPath, 'r', encoding='latin-1') as file:\n","    for line in file:\n","      word = line.strip()\n","      if word:\n","        negativeWords.add(word.lower())\n","\n","  print(\"Positive words:\", positiveWords)\n","  print(\"Negative words:\", negativeWords)\n","\n","  outputFile = \"/content/drive/MyDrive/BLACKCOFFER SOLUTION/Output.xlsx\"\n","  # Load input data\n","  inputDf = pd.read_excel(inputFile)\n","  outputRows = []\n","\n","  # iterate over each row in input Dataframe\n","  for index, row in inputDf.iterrows():\n","    urlID = row['URL_ID']\n","    filePath = os.path.join(extractionFolder, f\"{urlID}.txt\")\n","\n","    with open(filePath, 'r', encoding='utf-8') as file:\n","      articleText = file.read()\n","\n","    cleanedText = re.sub(r'[^\\w\\s]', '', articleText.lower())\n","    cleanedTextTokens = word_tokenize(cleanedText)\n","    cleanedTextTokens = [word for word in cleanedTextTokens if word not in stopWordsList]\n","\n","    positiveScore, negativeScore, polarityScore, subjectivityScore = calculateSentiment(cleanedTextTokens, positiveWords, negativeWords)\n","    avgSentenceLength, complexWordsPercentage, fogIndex, avgWordsPerSentence, complexWordCount, wordCount, syllablePerWord, personalPronouns, avgWordLength = calculateReadability(articleText)\n","\n","\n","    # Append metrics to output list\n","    outputRow = {**row, **{\"POSITIVE SCORE\": positiveScore, \"NEGATIVE SCORE\": negativeScore, \"POLARITY SCORE\": polarityScore, \"SUBJECTIVITY SCORE\": subjectivityScore, \"AVG SENTENCE LENGTH\": avgSentenceLength, \"PERCENTAGE OF COMPLEX WORDS\": complexWordsPercentage, \"FOG INDEX\": fogIndex, \"AVG NUMBER OF WORDS PER SENTENCE\": avgWordsPerSentence, \"COMPLEX WORD COUNT\": complexWordCount, \"WORD COUNT\": wordCount, \"SYLLABLE PER WORD\": syllablePerWord, \"PERSONAL PRONOUNS\": personalPronouns, \"AVG WORD LENGTH\": avgWordLength}}\n","    outputRows.append(outputRow)\n","\n","  # Convert list of dictionaries to DataFrame\n","  outputDf = pd.DataFrame(outputRows)\n","  # Save output to Excel file\n","  outputDf.to_excel(outputFile, index=False)\n"],"metadata":{"id":"ii0L0tknpDEl","executionInfo":{"status":"ok","timestamp":1715261620092,"user_tz":-330,"elapsed":6,"user":{"displayName":"21PW08 - JENISA MERLIN D","userId":"12343322897619244934"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","  main()"],"metadata":{"id":"iQCb9n72raG9"},"execution_count":null,"outputs":[]}]}